# Formative Assessment in MFL

## Introduction

Formative assessment lies at the heart of effective modern foreign language teaching. Unlike summative assessment, which evaluates learning at the end of a unit or course, formative assessment—often referred to as Assessment for Learning (AfL)—is an ongoing process that provides teachers with continuous information about pupil progress. This intelligence enables teachers to adjust their instruction in real-time, addressing misconceptions before they become entrenched and ensuring that all pupils make sustained progress in their language learning journey.

The Education Endowment Foundation (EEF) has identified embedding formative assessment as one of the most cost-effective approaches to improving pupil attainment, with an average impact of approximately four months' additional progress per year. In the context of MFL, where pupils must acquire complex phonological, grammatical, and lexical systems simultaneously, the strategic use of formative assessment becomes not merely beneficial but essential. This knowledge base entry explores the theoretical foundations and practical applications of formative assessment in MFL, with particular attention to low-stakes testing, retrieval practice, and feedback strategies.

## Theoretical Foundations of Formative Assessment

### Defining Formative Assessment

Formative assessment encompasses all those activities undertaken by teachers—and by their students—that provide information to be used as feedback to modify teaching and learning activities. Black and Wiliam's seminal 1998 research, "Inside the Black Box," established that formative assessment, when properly implemented, can yield significant learning gains, particularly for lower-attaining pupils. The Commission on Assessment without Levels (2015) reinforced this position, emphasising that in-class formative assessment is a vital part of teaching and learning, capable of providing teachers with rich diagnostic information about pupil understanding.

In MFL specifically, formative assessment must account for the unique challenges of language acquisition. Pupils are not merely learning facts about a language; they are developing procedural knowledge that must become automatic through repeated practice. This distinction has profound implications for how we assess progress. A pupil may understand the rules of French past tense formation (declarative knowledge) but still struggle to use them accurately in spontaneous communication (procedural knowledge). Effective formative assessment in MFL must therefore evaluate both knowledge and the ability to deploy that knowledge under real-time communicative pressure.

### The Role of Working Memory

Understanding formative assessment in MFL requires appreciation of cognitive architecture, particularly the constraints of working memory. When pupils encounter new language, their working memory is heavily taxed as they simultaneously process pronunciation, vocabulary meaning, grammatical structures, and communicative intent. Formative assessment serves as a diagnostic tool to determine whether language elements have been sufficiently practised to move from working memory into long-term memory, where they can be accessed automatically.

This cognitive perspective explains why low-stakes testing and retrieval practice are such powerful formative tools. Each act of retrieval strengthens the neural pathways associated with that knowledge, making future retrieval easier and more reliable. For MFL teachers, this means that the frequency and quality of opportunities for pupils to retrieve and use language are more important indicators of progress than isolated summative performances.

## Low-Stakes Testing

### Principles and Purposes

Low-stakes testing refers to frequent, informal assessments that carry minimal or no grade penalty. These assessments serve a diagnostic rather than evaluative function, creating a classroom culture where mistakes are viewed as learning opportunities rather than failures. In MFL, low-stakes testing is particularly valuable because language learning requires extensive memorisation of vocabulary and grammatical patterns—content that benefits enormously from regular retrieval practice.

The key distinction between low-stakes and high-stakes assessment lies in their emotional and motivational impact. High-stakes tests can trigger anxiety, which negatively affects working memory capacity and particularly impairs language performance. Low-stakes tests, by contrast, create what linguist Stephen Krashen termed a "low affective filter" environment, where pupils feel psychologically safe to experiment, make errors, and learn from them. This psychological safety is especially important in MFL, where pupils must overcome natural self-consciousness about pronunciation and fear of making public errors.

### Practical Applications in MFL

#### Vocabulary Retrieval Quizzes

The most common form of low-stakes testing in MFL is the vocabulary quiz. However, effective vocabulary testing goes far beyond simple word-for-word translation. Research by vocabulary acquisition specialist Paul Nation suggests that knowing a word involves multiple dimensions: form (spoken and written), meaning, and use. Formative vocabulary assessment should therefore sample from these different knowledge types.

Effective low-stakes vocabulary tests might include:

**Recognition tasks**: Pupils match target language words to English meanings or images. These tasks are relatively undemanding and suitable for early stages of vocabulary acquisition.

**Recall tasks**: Pupils translate English words into the target language without prompts. This requires more demanding retrieval and provides better diagnostic information about whether vocabulary has been fully learned.

**Gap-fill activities**: Pupils complete sentences by supplying appropriate vocabulary items in correct grammatical forms. This tests both vocabulary knowledge and the ability to use words grammatically.

**Translation sentences**: Short sentences requiring pupils to deploy multiple vocabulary items in context, testing integration of vocabulary with grammatical knowledge.

The timing of vocabulary quizzes matters significantly. Testing immediately after teaching yields inflated results that do not reflect durable learning. Effective formative assessment spaces quizzes across days and weeks, providing information about what has actually been retained rather than what is merely familiar in the moment.

#### Grammar Spot Checks

Grammar is another domain where low-stakes testing proves invaluable. Rather than relying solely on end-of-unit assessments that may reveal gaps too late for remediation, teachers can use brief "grammar spot checks" at lesson beginnings or transitions. These might involve:

- Conjugating a single verb in multiple tenses
- Identifying errors in presented sentences
- Transforming sentences from one tense to another
- Selecting appropriate grammatical forms in multiple-choice format

The key is brevity and regularity. A two-minute spot check on three grammar points provides more useful formative information than a thirty-minute test covering twenty points, particularly when followed by immediate feedback and targeted reteaching.

#### Phonological Awareness Checks

MFL presents unique challenges in phonological processing, as pupils must learn to perceive and produce sounds that may not exist in English. Low-stakes phonological assessment might include:

- Minimal pair discrimination (distinguishing between similar sounds)
- Dictation of single words or short phrases
- Reading aloud with teacher monitoring
- Shadowing exercises where pupils repeat after a native speaker recording

These assessments should focus on progress rather than absolute accuracy, celebrating improvement over time and identifying specific sounds or patterns requiring additional practice.

### Designing Effective Low-Stakes Tests

The design of low-stakes tests significantly influences their formative value. Tests that are too easy provide no diagnostic information; tests that are too difficult discourage pupils and may yield false negatives. Effective low-stakes tests should target the "zone of proximal development"—content that pupils can master with appropriate support.

Spacing is another critical design consideration. Research by Hermann Ebbinghaus and subsequent cognitive psychologists has demonstrated that spaced retrieval produces more durable learning than massed practice. Low-stakes tests should therefore revisit content from previous weeks and months, not just recent lessons. This interleaving of old and new content provides teachers with information about long-term retention and signals to pupils that language learning is cumulative.

## Retrieval Practice

### The Science of Retrieval

Retrieval practice—also known as the testing effect—refers to the phenomenon where the act of retrieving information from memory strengthens that memory, making it easier to retrieve in the future. This counterintuitive finding, robustly established across hundreds of studies, suggests that testing is not merely a measurement tool but a powerful learning strategy in its own right.

The mechanism underlying retrieval practice involves memory consolidation. When we successfully retrieve information, we activate the neural pathways associated with that knowledge, strengthening the synaptic connections and often adding contextual details that enrich the memory trace. In MFL, this means that every time a pupil successfully retrieves a vocabulary item or grammatical rule, their knowledge becomes more durable and more accessible.

### Retrieval Practice in MFL

#### Vocabulary Retrieval Strategies

Vocabulary forms the bedrock of language proficiency, and retrieval practice offers powerful tools for ensuring that vocabulary moves from fragile, easily forgotten traces to robust, automatically accessible knowledge. Several retrieval strategies have proven particularly effective in MFL contexts:

**Flashcard systems**: Whether physical or digital (such as Anki or Quizlet), flashcards implement spaced retrieval by presenting items at intervals optimised for each learner's performance history. When a pupil successfully retrieves a word, the interval before its next presentation increases; when retrieval fails, the interval decreases. This adaptive spacing maximises learning efficiency.

**The Dice Game Strategy**: In this approach, pupils receive numbered lists of vocabulary. In groups, they take turns rolling dice and then defining or translating the word corresponding to the number rolled. The randomness ensures unpredictable retrieval, which produces stronger memory benefits than predictable sequences.

**The Fishbowl Strategy**: Prompts are written on slips of paper and placed in a container. Pupils draw prompts, perform retrieval practice, and then discuss with a partner. This combines individual retrieval with collaborative processing, allowing pupils to benefit from peer explanation and correction.

**Translation dictation**: The teacher dictates short sentences in English that pupils translate into the target language. This requires simultaneous retrieval of vocabulary and grammatical knowledge, with the added benefit of testing whether pupils can produce correct spellings and forms under time pressure.

#### Grammatical Retrieval

Grammar retrieval practice must go beyond simple rule recitation to test whether pupils can apply grammatical knowledge in communicative contexts. Effective grammatical retrieval activities include:

**Sentence transformation**: Pupils rewrite sentences, changing tense, voice, or modality. For example, transforming "J'ai mangé une pomme" (passé composé) to "Je mangeais une pomme" (imparfait) requires understanding of both tenses and their distinct uses.

**Error correction**: Presenting sentences containing deliberate errors and requiring pupils to identify and correct them. This develops grammatical vigilance—the ability to monitor one's own output for accuracy.

**Conjugation drills**: While traditional conjugation tables have fallen out of favour, targeted conjugation retrieval—focusing on high-frequency irregular verbs or problematic patterns—remains valuable for developing automaticity.

**Gap-fill with options removed**: Unlike traditional cloze exercises where multiple-choice options provide scaffolding, requiring pupils to supply appropriate words or forms without prompts demands more complete retrieval and provides better diagnostic information.

#### Speaking and Listening Retrieval

The productive skills of speaking and the receptive skill of listening also benefit from retrieval practice, though these are more challenging to implement in whole-class settings:

**Delayed copying**: The teacher displays a sentence briefly, then removes it. After a delay, pupils write what they remember. This exercises both memory and accurate reproduction of target language forms.

**Retrieval roulette**: A game format where pupils take turns retrieving vocabulary or grammar under time pressure, with points awarded for correct responses. The competitive element increases engagement and retrieval effort.

**Audio flashcards**: Digital systems that play target language audio, requiring pupils to produce the correct written form or translation before revealing the answer. This develops the crucial skill of decoding spoken language.

### Spacing and Interleaving

The benefits of retrieval practice are substantially enhanced by two related principles: spacing and interleaving. Spacing refers to distributing practice across time rather than massing it in single sessions. Interleaving refers to mixing different types of content rather than blocking practice of single topics.

In MFL, spacing might involve returning to vocabulary from previous topics rather than testing only current content. Interleaving might involve mixing different verb tenses in retrieval practice rather than practising each tense in isolation. Research consistently shows that while blocked practice produces better immediate performance, spaced and interleaved practice produces superior long-term retention and transfer.

For teachers implementing formative assessment, this means designing retrieval opportunities that deliberately revisit old content and mix different knowledge types. A retrieval quiz that includes vocabulary from three different topics and grammar from two different units will provide more valid information about durable learning than a quiz focused solely on recent lessons.

## Feedback in MFL

### The Role of Feedback in Language Learning

Feedback is the informational component that transforms assessment into a learning tool. Without feedback, pupils may continue practising errors, embedding misconceptions that become increasingly difficult to unlearn. In MFL, feedback serves multiple functions: it corrects linguistic errors, provides models of target-like performance, builds metalinguistic awareness, and motivates continued effort.

The effectiveness of feedback depends critically on its timing, form, and focus. Immediate feedback is generally more effective for factual learning and error correction, while delayed feedback may promote deeper processing and self-monitoring. In MFL, the distinction between errors (systematic deviations reflecting gaps in knowledge) and mistakes (performance lapses that the pupil could self-correct) has important implications for feedback timing—errors require immediate correction, while pupils might benefit from opportunities to self-correct mistakes.

### Types of Feedback

#### Corrective Feedback on Oral Production

When pupils speak in the target language, teachers face constant decisions about whether and how to correct errors. Research on corrective feedback has identified several effective approaches:

**Recasts**: The teacher reformulates the pupil's utterance, maintaining the meaning but correcting the form. For example:
- Pupil: "*Je voudrais deux pommes rouges."
- Teacher: "Ah, vous voudriez deux pommes rouges?"

Recasts are unobtrusive and maintain communicative flow, but research suggests they may be less effective than more explicit feedback types because pupils often fail to notice the correction.

**Prompts**: The teacher signals that an error has occurred without providing the correction, encouraging self-repair. Prompts might include clarification requests ("What do you mean?"), repetitions with questioning intonation, or metalinguistic clues ("Check the gender of that noun").

**Explicit correction**: The teacher clearly indicates that an error has occurred and provides the correct form. While more intrusive, explicit correction ensures that pupils notice the gap between their production and the target.

**Elicitation**: The teacher attempts to elicit the correct form from the pupil through questions or prompts: "How do we say that in the past tense?"

The choice among these feedback types should consider the error type, the pupil's proficiency level, the lesson focus, and the communicative context. Formative assessment involves monitoring whether pupils are incorporating feedback into subsequent productions—a sign that feedback has been noticed and processed.

#### Written Feedback

Written work provides opportunities for more detailed and considered feedback than is possible in spontaneous speech. However, the effectiveness of written feedback depends on how it is designed and delivered:

**Direct vs. indirect feedback**: Direct feedback supplies the correct form; indirect feedback signals that an error exists without providing the correction. Research suggests that direct feedback is more effective for grammatical errors and for lower-proficiency learners, while indirect feedback may promote deeper processing and self-monitoring for advanced learners.

**Focused vs. unfocused feedback**: Focused feedback targets specific error types identified as priorities, while unfocused feedback addresses all errors. Given the limited capacity of working memory and the danger of overwhelming pupils with excessive correction, focused feedback is generally more effective.

**Coded feedback**: Using a system of codes or symbols to indicate error types (e.g., VT for verb tense, SP for spelling) encourages pupils to engage with their errors and develop metalinguistic awareness. However, coded feedback requires training and may be less suitable for younger learners.

**Written commentary**: Beyond error correction, written commentary can provide praise, pose questions to extend thinking, suggest strategies for improvement, and establish connections to learning objectives. Such commentary transforms feedback from mere correction into a dialogue about learning.

### Peer and Self-Assessment

Formative assessment in MFL need not be solely teacher-directed. Peer and self-assessment develop metacognitive skills and promote learner autonomy—crucial outcomes for lifelong language learning.

**Peer assessment**: When pupils assess each other's work using clear criteria and rubrics, they engage deeply with quality standards and develop analytical skills. Pair work activities where pupils check each other's pronunciation or written work provide natural opportunities for peer feedback. Teachers must establish classroom norms that make peer assessment supportive rather than critical, and should monitor peer interactions to ensure feedback quality.

**Self-assessment**: Developing pupils' ability to assess their own progress is a fundamental goal of formative assessment. Self-assessment might involve:
- Traffic light systems where pupils indicate confidence levels
- Checklists of learning objectives for self-monitoring
- Recording and reviewing one's own spoken production
- Reflective writing about learning strategies and progress

Research by Hattie and Timperley emphasises that self-assessment is most effective when pupils have clear learning intentions and success criteria. In MFL, this means sharing not just what pupils will learn but what successful performance looks like at different levels.

### The Timing of Feedback

Feedback timing presents a tension in formative assessment. Immediate feedback ensures that errors do not become practised and provides opportunities for immediate correction. However, delayed feedback may encourage deeper processing and develop self-monitoring skills.

In MFL, a balanced approach is generally most effective:
- **Immediate feedback** for pronunciation errors during controlled practice, grammatical errors during accuracy-focused activities, and vocabulary errors during initial learning phases
- **Delayed feedback** during fluency-focused activities where interruption would disrupt communication, and for self-monitoring activities where pupils are encouraged to identify their own errors

Technology can help resolve this tension by providing immediate feedback on form-focused exercises while preserving communicative flow during meaning-focused activities. Language learning apps and computer-assisted language learning systems can offer instant correction for appropriate exercise types, freeing teacher attention for higher-level feedback during communicative tasks.

## Integrating Formative Assessment into MFL Pedagogy

### Questioning Strategies

Teacher questioning is perhaps the most frequently used formative assessment tool. The quality of questioning significantly influences the quality of information gathered about pupil learning.

**Wait time**: Extending the time between asking a question and accepting a response (wait time 1) and between the response and teacher feedback (wait time 2) increases the length and complexity of pupil responses. In MFL, where pupils must formulate responses in a second language, adequate wait time is essential for allowing cognitive processing.

**Open vs. closed questions**: Closed questions (yes/no, single-word answers) provide limited diagnostic information but can efficiently check basic comprehension. Open questions requiring explanation, justification, or extended response provide richer information about depth of understanding.

**Bloom's taxonomy**: Questions can target different cognitive levels, from recall of vocabulary through analysis of grammatical patterns to evaluation of communicative effectiveness. Formative assessment should sample across these levels to build a complete picture of pupil capabilities.

**No hands up**: Strategies that avoid relying on volunteers (such as random selection or whole-class response systems) ensure that all pupils engage with questions rather than opting out, providing more valid information about class-wide understanding.

**Hinge questions**